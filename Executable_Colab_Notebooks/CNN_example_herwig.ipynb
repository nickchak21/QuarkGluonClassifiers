{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_example_herwig.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickchak21/QuarkGluonClassifiers/blob/master/Executable_Colab_Notebooks/CNN_example_herwig.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDQHdFMzRKws",
        "colab_type": "code",
        "outputId": "043c17cd-cf3d-4a6c-f372-54b0fdce6153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip install energyflow\n",
        "!pip install h5py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting energyflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/ba/f598bafbde78553b962dc1f693ef95365cc752ddbdb448856858093579eb/EnergyFlow-1.0.0-py2.py3-none-any.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from energyflow) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from energyflow) (1.17.4)\n",
            "Collecting h5py>=2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 38.7MB/s \n",
            "\u001b[?25hInstalling collected packages: h5py, energyflow\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "Successfully installed energyflow-1.0.0 h5py-2.10.0\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCY1hm8xSJyX",
        "colab_type": "code",
        "outputId": "fae4cde8-71b6-43ff-8134-d0304a95fb41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r3rd5lMSYiH",
        "colab_type": "code",
        "outputId": "7683d828-5902-4f28-c3fc-5d4b5abc55b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install POT"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting POT\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/36/07d3c0960a590b88b81fa1837e666cc7479b90c7e9fd1063024ce9331122/POT-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (305kB)\n",
            "\r\u001b[K     |█                               | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 122kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 163kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 174kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 184kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 194kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 204kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 215kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 225kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 235kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 245kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 256kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 266kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 276kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 286kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 296kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from POT) (1.3.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from POT) (0.29.14)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from POT) (1.17.4)\n",
            "Installing collected packages: POT\n",
            "Successfully installed POT-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjupFyDlShn7",
        "colab_type": "code",
        "outputId": "6d081c85-f282-46b7-f68c-3a471fc16417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!python -c \"import energyflow; energyflow.utils.get_examples()\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading efp_example.py from https://github.com/pkomiske/EnergyFlow/raw/master/examples/efp_example.py to /root/.energyflow/examples\n",
            "Downloading cnn_example.py from https://github.com/pkomiske/EnergyFlow/raw/master/examples/cnn_example.py to /root/.energyflow/examples\n",
            "Downloading dnn_example.py from https://github.com/pkomiske/EnergyFlow/raw/master/examples/dnn_example.py to /root/.energyflow/examples\n",
            "Downloading pfn_example.py from https://github.com/pkomiske/EnergyFlow/raw/master/examples/pfn_example.py to /root/.energyflow/examples\n",
            "Downloading efn_example.py from https://github.com/pkomiske/EnergyFlow/raw/master/examples/efn_example.py to /root/.energyflow/examples\n",
            "\n",
            "Summary of examples:\n",
            "efp_example.py exists at /root/.energyflow/examples\n",
            "cnn_example.py exists at /root/.energyflow/examples\n",
            "dnn_example.py exists at /root/.energyflow/examples\n",
            "pfn_example.py exists at /root/.energyflow/examples\n",
            "efn_example.py exists at /root/.energyflow/examples\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWpFGI3jtgkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /root/.energyflow/examples/cnn_example.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxJOwhR7tWcu",
        "colab_type": "code",
        "outputId": "d00629fe-ef32-45e3-8dba-5105d59ff123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /root/.energyflow/examples/cnn_example.py\n",
        "\"\"\"An example involving jet images and convolutional neural networks (CNNs).\n",
        "The [`CNN`](../docs/archs/#cnn) class is used to provide a network architecture\n",
        "based on that described in [1612.01551](https://arxiv.org/abs/1612.01551). \n",
        "\n",
        "Jet images are constructed using the [`pixelate`](../docs/utils/#pixelate) \n",
        "function and can be either one-channel (grayscale), meaning that only \n",
        "$p_T$ information is used, or two-channel (color), meaning that $p_T$\n",
        "information and local charged particle counts are used. The images are\n",
        "preprocessed by subtracting the average image in the training set and\n",
        "dividing by the per-pixel standard deviations, using the \n",
        "[`zero_center`](../docs/utils/#zero_center) and \n",
        "[`standardize`](../docs/utils/#standardize) functions, respectively. \n",
        "The output of the example is a plot of the ROC curves of the CNN \n",
        "as well as the jet mass and constituent multiplicity observables.\n",
        "\n",
        "Note that the number of epochs is quite small because it is quite time\n",
        "consuming to train a CNN without a GPU (which will speed up this example\n",
        "immensely).\n",
        "\"\"\"\n",
        "\n",
        "# standard library imports\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# standard numerical library imports\n",
        "import numpy as np\n",
        "\n",
        "# energyflow imports\n",
        "import energyflow as ef\n",
        "from energyflow.archs import CNN\n",
        "from energyflow.datasets import qg_jets\n",
        "from energyflow.utils import data_split, pixelate, standardize, to_categorical, zero_center\n",
        "\n",
        "# attempt to import sklearn\n",
        "try:\n",
        "    from sklearn.metrics import roc_auc_score, roc_curve\n",
        "except:\n",
        "    print('please install scikit-learn in order to make ROC curves')\n",
        "    roc_curve = False\n",
        "\n",
        "# attempt to import matplotlib\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "except:\n",
        "    print('please install matploltib in order to make plots')\n",
        "    plt = False\n",
        "\n",
        "################################### SETTINGS ###################################\n",
        "\n",
        "# data controls\n",
        "num_data = 220000\n",
        "val_frac, test_frac = 0.1, 0.15\n",
        "\n",
        "# image parameters\n",
        "R = 0.4\n",
        "img_width = 2*R\n",
        "npix = 33\n",
        "nb_chan = 2\n",
        "norm = True\n",
        "\n",
        "# required network architecture parameters\n",
        "input_shape = (nb_chan, npix, npix)\n",
        "filter_sizes = [8, 4, 4]\n",
        "num_filters = [8, 8, 8] # very small so can run on non-GPUs in reasonable time\n",
        "\n",
        "# optional network architecture parameters\n",
        "dense_sizes = [50]\n",
        "pool_sizes = 2\n",
        "\n",
        "# network training parameters\n",
        "num_epoch = 15\n",
        "batch_size = 100\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# load data\n",
        "X, y = qg_jets.load(num_data=num_data, generator='herwig')\n",
        "\n",
        "# convert labels to categorical\n",
        "Y = to_categorical(y, num_classes=2)\n",
        "\n",
        "print('Loaded quark and gluon jets')\n",
        "\n",
        "# make jet images\n",
        "images = np.asarray([pixelate(x, npix=npix, img_width=img_width, nb_chan=nb_chan, \n",
        "                                 charged_counts_only=True, norm=norm) for x in X])\n",
        "\n",
        "print('Done making jet images')\n",
        "\n",
        "# do train/val/test split \n",
        "(X_train, X_val, X_test,\n",
        " Y_train, Y_val, Y_test) = data_split(images, Y, val=val_frac, test=test_frac)\n",
        "\n",
        "print('Done train/val/test split')\n",
        "\n",
        "# preprocess by zero centering images and standardizing each pixel\n",
        "X_train, X_val, X_test = standardize(*zero_center(X_train, X_val, X_test))\n",
        "\n",
        "print('Finished preprocessing')\n",
        "print('Model summary:')\n",
        "\n",
        "# build architecture\n",
        "hps = {'input_shape': input_shape,\n",
        "       'filter_sizes': filter_sizes,\n",
        "       'num_filters': num_filters,\n",
        "       'dense_sizes': dense_sizes,\n",
        "       'pool_sizes': pool_sizes}\n",
        "cnn = CNN(hps)\n",
        "\n",
        "# train model\n",
        "cnn.fit(X_train, Y_train,\n",
        "          epochs=num_epoch,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_val, Y_val),\n",
        "          verbose=1)\n",
        "\n",
        "# get predictions on test data\n",
        "preds = cnn.predict(X_test, batch_size=1000)\n",
        "\n",
        "# get ROC curve if we have sklearn\n",
        "if roc_curve:\n",
        "    cnn_fp, cnn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
        "\n",
        "    # get area under the ROC curve\n",
        "    auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
        "    print()\n",
        "    print('CNN AUC:', auc)\n",
        "    print()\n",
        "\n",
        "    # make ROC curve plot if we have matplotlib\n",
        "    if plt:\n",
        "\n",
        "        # get multiplicity and mass for comparison\n",
        "        masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X])\n",
        "        mults = np.asarray([np.count_nonzero(x[:,0]) for x in X])\n",
        "        mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses)\n",
        "        mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults)\n",
        "\n",
        "        # some nicer plot settings \n",
        "        plt.rcParams['figure.figsize'] = (4,4)\n",
        "        plt.rcParams['font.family'] = 'serif'\n",
        "        plt.rcParams['figure.autolayout'] = True\n",
        "\n",
        "        # plot the ROC curves\n",
        "        plt.plot(cnn_tp, 1-cnn_fp, '-', color='black', label='CNN')\n",
        "        plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass')\n",
        "        plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity')\n",
        "\n",
        "        # axes labels\n",
        "        plt.xlabel('Quark Jet Efficiency')\n",
        "        plt.ylabel('Gluon Jet Rejection')\n",
        "\n",
        "        # axes limits\n",
        "        plt.xlim(0, 1)\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        # make legend and show plot\n",
        "        plt.legend(loc='lower left', frameon=False)\n",
        "        plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /root/.energyflow/examples/cnn_example.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq8SY4RuSl6B",
        "colab_type": "code",
        "outputId": "a56c2fc5-1c2f-4af1-b821-cd472d168083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /root/.energyflow/examples/cnn_example.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Downloading QG_jets_herwig_0.npz from https://www.dropbox.com/s/xizexr2tjq2bm59/QG_jets_herwig_0.npz?dl=1 to /root/.energyflow/datasets\n",
            "Downloading QG_jets_herwig_1.npz from https://www.dropbox.com/s/ym675q2ui3ik3n9/QG_jets_herwig_1.npz?dl=1 to /root/.energyflow/datasets\n",
            "Downloading QG_jets_herwig_2.npz from https://www.dropbox.com/s/qic6ejl27y6vpqj/QG_jets_herwig_2.npz?dl=1 to /root/.energyflow/datasets\n",
            "tcmalloc: large alloc 1382400000 bytes == 0x8f70a000 @  0x7f22aebed1e7 0x7f22ac74cf71 0x7f22ac7b055d 0x7f22ac7b0733 0x7f22ac84e768 0x7f22ac84efc4 0x7f22ac84f112 0x5673a3 0x5a04ce 0x7f22ac79c06d 0x50a84f 0x50c549 0x5081d5 0x50a020 0x50aa1d 0x50c549 0x5081d5 0x5895e1 0x5a04ce 0x7f22ac79c06d 0x50a84f 0x50c549 0x5081d5 0x50a020 0x50aa1d 0x50c549 0x5081d5 0x50a020 0x50aa1d 0x50d320 0x5081d5\n",
            "Loaded quark and gluon jets\n",
            "tcmalloc: large alloc 3833282560 bytes == 0x16659e000 @  0x7f22aebed1e7 0x7f22ac74cf71 0x7f22ac7b055d 0x7f22ac7b3e28 0x7f22ac7b43e5 0x7f22ac84afc2 0x50abc5 0x50d320 0x5081d5 0x50a020 0x50aa1d 0x50c549 0x5081d5 0x50b3a3 0x635082 0x635137 0x6388ef 0x639491 0x4b0f60 0x7f22ae7eab97 0x5b2eaa\n",
            "Done making jet images\n",
            "tcmalloc: large alloc 2874966016 bytes == 0x24ad52000 @  0x7f22aebed1e7 0x7f22ac74cf71 0x7f22ac7b055d 0x7f22ac7b0733 0x7f22ac83ba2a 0x7f22ac83be78 0x50c81e 0x5081d5 0x50a020 0x50aa1d 0x50c549 0x5081d5 0x50a020 0x50aa1d 0x50d320 0x5081d5 0x50b3a3 0x635082 0x635137 0x6388ef 0x639491 0x4b0f60 0x7f22ae7eab97 0x5b2eaa\n",
            "Done train/val/test split\n",
            "tcmalloc: large alloc 2874966016 bytes == 0x318fbc000 @  0x7f22aebed1e7 0x7f22ac74cf71 0x7f22ac7b055d 0x7f22ac7b0733 0x7f22ac8638cd 0x7f22ac86422e 0x7f22ac866ba8 0x7f22ac9b0286 0x7f22ac9b1da4 0x7f22ac9b44f2 0x7f22ac9b536e 0x5a508c 0x5a5758 0x7f22ac86eafb 0x59d0f2 0x50d0ff 0x5081d5 0x50a020 0x50aa1d 0x50d320 0x5081d5 0x5896fc 0x5a04ce 0x50d8f5 0x5081d5 0x5896fc 0x5a04ce 0x7f22ac79c06d 0x50a84f 0x50c549 0x5081d5\n",
            "Finished preprocessing\n",
            "Model summary:\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-11-17 16:53:02.287804: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-11-17 16:53:02.288366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x585ae00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-17 16:53:02.288399: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-11-17 16:53:02.365262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-11-17 16:53:02.552606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-17 16:53:02.553557: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x585ac40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-17 16:53:02.553591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-11-17 16:53:02.554176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-17 16:53:02.555057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-11-17 16:53:02.583858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-17 16:53:02.783854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-17 16:53:02.884738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-11-17 16:53:02.909974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-11-17 16:53:03.133925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-11-17 16:53:03.315317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-11-17 16:53:03.796433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-11-17 16:53:03.799584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-17 16:53:03.800500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-17 16:53:03.808830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-11-17 16:53:03.812839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-11-17 16:53:03.821659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-11-17 16:53:03.824448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-11-17 16:53:03.824487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-11-17 16:53:03.835762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-17 16:53:03.836557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-11-17 16:53:03.845856: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-11-17 16:53:03.848572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_0 (Conv2D)            (None, 8, 26, 26)         1032      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 8, 26, 26)         0         \n",
            "_________________________________________________________________\n",
            "max_pool_0 (MaxPooling2D)    (None, 4, 13, 26)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 10, 23)         520       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 8, 10, 23)         0         \n",
            "_________________________________________________________________\n",
            "max_pool_1 (MaxPooling2D)    (None, 4, 5, 23)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 2, 20)          520       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 2, 20)          0         \n",
            "_________________________________________________________________\n",
            "max_pool_2 (MaxPooling2D)    (None, 4, 1, 20)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_0 (Dense)              (None, 50)                4050      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2)                 102       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 6,224\n",
            "Trainable params: 6,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 165000 samples, validate on 22000 samples\n",
            "Epoch 1/15\n",
            "2019-11-17 16:53:07.903427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-11-17 16:53:08.646835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "165000/165000 [==============================] - 21s 130us/step - loss: 0.5758 - acc: 0.7019 - val_loss: 0.5631 - val_acc: 0.7131\n",
            "Epoch 2/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5580 - acc: 0.7188 - val_loss: 0.5557 - val_acc: 0.7206\n",
            "Epoch 3/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5530 - acc: 0.7220 - val_loss: 0.5543 - val_acc: 0.7231\n",
            "Epoch 4/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5495 - acc: 0.7256 - val_loss: 0.5563 - val_acc: 0.7190\n",
            "Epoch 5/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5476 - acc: 0.7265 - val_loss: 0.5494 - val_acc: 0.7233\n",
            "Epoch 6/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5455 - acc: 0.7280 - val_loss: 0.5561 - val_acc: 0.7219\n",
            "Epoch 7/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5441 - acc: 0.7295 - val_loss: 0.5491 - val_acc: 0.7260\n",
            "Epoch 8/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5426 - acc: 0.7309 - val_loss: 0.5471 - val_acc: 0.7246\n",
            "Epoch 9/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5418 - acc: 0.7311 - val_loss: 0.5470 - val_acc: 0.7249\n",
            "Epoch 10/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5408 - acc: 0.7321 - val_loss: 0.5471 - val_acc: 0.7268\n",
            "Epoch 11/15\n",
            "165000/165000 [==============================] - 18s 108us/step - loss: 0.5405 - acc: 0.7323 - val_loss: 0.5466 - val_acc: 0.7264\n",
            "Epoch 12/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5394 - acc: 0.7323 - val_loss: 0.5470 - val_acc: 0.7251\n",
            "Epoch 13/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5389 - acc: 0.7325 - val_loss: 0.5480 - val_acc: 0.7258\n",
            "Epoch 14/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5381 - acc: 0.7336 - val_loss: 0.5469 - val_acc: 0.7251\n",
            "Epoch 15/15\n",
            "165000/165000 [==============================] - 18s 107us/step - loss: 0.5373 - acc: 0.7341 - val_loss: 0.5481 - val_acc: 0.7230\n",
            "\n",
            "CNN AUC: 0.8002557861301091\n",
            "\n",
            "<Figure size 400x400 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SKohJLeizyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}